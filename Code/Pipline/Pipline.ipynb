{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75401,
     "status": "error",
     "timestamp": 1556727122761,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "H4_rgcWjC1wQ",
    "outputId": "4f67fd54-1f4d-4f3d-c880-0db8b5ab9e3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E: Package 'python-software-properties' has no installation candidate\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "from oauth2client.client import GoogleCredentials\n",
    "from google.colab import auth\n",
    "!apt-get install - y - qq software-properties-common python-software-properties module-init-tools\n",
    "!add-apt-repository - y ppa: alessandro-strada/ppa 2 > &1 > /dev/null\n",
    "!apt-get update - qq 2 > &1 > /dev/null\n",
    "!apt-get - y install - qq google-drive-ocamlfuse fuse\n",
    "auth.authenticate_user()\n",
    "creds = GoogleCredentials.get_application_default()\n",
    "!google-drive-ocamlfuse - headless - id = {creds.client_id} - secret = {creds.client_secret} < /dev/null 2 > &1 | grep URL\n",
    "vcode = getpass.getpass()\n",
    "!echo {vcode} | google-drive-ocamlfuse - headless - id = {creds.client_id} - secret = {creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAEXzMr_DOTo"
   },
   "outputs": [],
   "source": [
    "!mkdir - p drive\n",
    "!google-drive-ocamlfuse drive - o nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MCDdayZDDVVs"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3270,
     "status": "ok",
     "timestamp": 1556727041091,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "6AH8_4oADX8R",
    "outputId": "de369089-fcfc-4d3d-8fbd-17517f9d4a92"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access 'Competitions/KDD-Cup-2019-CAMMTR/Data': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls Competitions/KDD-Cup-2019-CAMMTR/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:58:54.938235Z",
     "start_time": "2019-05-01T16:58:54.932067Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "SUGolQaUDblG"
   },
   "outputs": [],
   "source": [
    "# project_path='./Competitions/KDD-Cup-2019-CAMMTR/'\n",
    "project_path = '../../'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:58:57.250276Z",
     "start_time": "2019-05-01T16:58:56.236271Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OxlyOW7bCvXc"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from itertools import product\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "holidays = pd.Series(\n",
    "    json.load(open(project_path+r'Data/Holidays.json'))['holidays'])\n",
    "subwayinfo = pd.read_csv(project_path+r'Data/BeijingSubway.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJFW6SL_CvXf"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:58:57.293921Z",
     "start_time": "2019-05-01T16:58:57.285194Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kCAkXW4fCvXg"
   },
   "outputs": [],
   "source": [
    "def load_data(mainpath):\n",
    "    train_queries = pd.read_csv(\n",
    "        mainpath + 'train_queries.csv', parse_dates=['req_time'])\n",
    "    train_plans = pd.read_csv(mainpath + 'train_plans.csv',\n",
    "                              parse_dates=['plan_time'])\n",
    "    train_clicks = pd.read_csv(mainpath + 'train_clicks.csv')\n",
    "    profiles = pd.read_csv(mainpath + 'profiles.csv')\n",
    "    test_queries = pd.read_csv(\n",
    "        mainpath + 'test_queries.csv', parse_dates=['req_time'])\n",
    "    test_plans = pd.read_csv(mainpath + 'test_plans.csv',\n",
    "                             parse_dates=['plan_time'])\n",
    "    return train_queries, train_plans, train_clicks, profiles, test_queries, test_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:58:58.837943Z",
     "start_time": "2019-05-01T16:58:58.824048Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iUQcoS3ACvXi"
   },
   "outputs": [],
   "source": [
    "def merge(train_queries, train_plans, train_clicks, profiles, test_queries, test_plans):\n",
    "    train = train_queries.merge(train_plans, 'left', ['sid'])\n",
    "    test = test_queries.merge(test_plans, 'left', ['sid'])\n",
    "    train = train.merge(train_clicks, 'left', ['sid'])\n",
    "    train['click_mode'] = train['click_mode'].fillna(0).astype(int)\n",
    "    data = pd.concat([train, test], ignore_index=True)\n",
    "    data = data.merge(profiles, 'left', ['pid'])\n",
    "    return train, test, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:03.588236Z",
     "start_time": "2019-05-01T16:59:03.535944Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ezvgAZ46CvXj"
   },
   "outputs": [],
   "source": [
    "def gen_plan_feas(data):\n",
    "    n = data.shape[0]\n",
    "    mode_list_feas = np.zeros((n, 12))\n",
    "    max_dist, min_dist, mean_dist, std_dist = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    max_price, min_price, mean_price, std_price = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    max_eta, min_eta, mean_eta, std_eta = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    min_dist_mode, max_dist_mode, min_price_mode, max_price_mode, min_eta_mode, max_eta_mode, first_mode = \\\n",
    "        np.zeros((n,)), np.zeros((n,)), np.zeros((n,)), np.zeros(\n",
    "            (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    mode_texts = []\n",
    "    for i, plan in tqdm(enumerate(data['plans_json'].values)):\n",
    "        if len(plan) == 0:\n",
    "            cur_plan_list = []\n",
    "        else:\n",
    "            cur_plan_list = plan\n",
    "        if len(cur_plan_list) == 0:\n",
    "            mode_list_feas[i, 0] = 1\n",
    "            first_mode[i] = 0\n",
    "            max_dist[i] = -1\n",
    "            min_dist[i] = -1\n",
    "            mean_dist[i] = -1\n",
    "            std_dist[i] = -1\n",
    "            max_price[i] = -1\n",
    "            min_price[i] = -1\n",
    "            mean_price[i] = -1\n",
    "            std_price[i] = -1\n",
    "            max_eta[i] = -1\n",
    "            min_eta[i] = -1\n",
    "            mean_eta[i] = -1\n",
    "            std_eta[i] = -1\n",
    "            min_dist_mode[i] = -1\n",
    "            max_dist_mode[i] = -1\n",
    "            min_price_mode[i] = -1\n",
    "            max_price_mode[i] = -1\n",
    "            min_eta_mode[i] = -1\n",
    "            max_eta_mode[i] = -1\n",
    "            mode_texts.append('word_null')\n",
    "        else:\n",
    "            distance_list = []\n",
    "            price_list = []\n",
    "            eta_list = []\n",
    "            mode_list = []\n",
    "            for tmp_dit in cur_plan_list:\n",
    "                distance_list.append(int(tmp_dit['distance']))\n",
    "                if tmp_dit['price'] == '':\n",
    "                    price_list.append(0)\n",
    "                else:\n",
    "                    price_list.append(int(tmp_dit['price']))\n",
    "                eta_list.append(int(tmp_dit['eta']))\n",
    "                mode_list.append(int(tmp_dit['transport_mode']))\n",
    "            mode_texts.append(\n",
    "                ' '.join(['word_{}'.format(mode) for mode in mode_list]))\n",
    "            distance_list = np.array(distance_list)\n",
    "            price_list = np.array(price_list)\n",
    "            eta_list = np.array(eta_list)\n",
    "            mode_list = np.array(mode_list, dtype='int')\n",
    "            mode_list_feas[i, mode_list] = 1\n",
    "            distance_sort_idx = np.argsort(distance_list)\n",
    "            price_sort_idx = np.argsort(price_list)\n",
    "            eta_sort_idx = np.argsort(eta_list)\n",
    "            max_dist[i] = distance_list[distance_sort_idx[-1]]\n",
    "            min_dist[i] = distance_list[distance_sort_idx[0]]\n",
    "            mean_dist[i] = np.mean(distance_list)\n",
    "            std_dist[i] = np.std(distance_list)\n",
    "            max_price[i] = price_list[price_sort_idx[-1]]\n",
    "            min_price[i] = price_list[price_sort_idx[0]]\n",
    "            mean_price[i] = np.mean(price_list)\n",
    "            std_price[i] = np.std(price_list)\n",
    "            max_eta[i] = eta_list[eta_sort_idx[-1]]\n",
    "            min_eta[i] = eta_list[eta_sort_idx[0]]\n",
    "            mean_eta[i] = np.mean(eta_list)\n",
    "            std_eta[i] = np.std(eta_list)\n",
    "            first_mode[i] = mode_list[0]\n",
    "            max_dist_mode[i] = mode_list[distance_sort_idx[-1]]\n",
    "            min_dist_mode[i] = mode_list[distance_sort_idx[0]]\n",
    "            max_price_mode[i] = mode_list[price_sort_idx[-1]]\n",
    "            min_price_mode[i] = mode_list[price_sort_idx[0]]\n",
    "            max_eta_mode[i] = mode_list[eta_sort_idx[-1]]\n",
    "            min_eta_mode[i] = mode_list[eta_sort_idx[0]]\n",
    "    feature_data = pd.DataFrame(mode_list_feas)\n",
    "    feature_data.columns = ['mode_feas_{}'.format(i) for i in range(12)]\n",
    "    feature_data['max_dist'] = max_dist\n",
    "    feature_data['min_dist'] = min_dist\n",
    "    feature_data['mean_dist'] = mean_dist\n",
    "    feature_data['std_dist'] = std_dist\n",
    "    feature_data['max_price'] = max_price\n",
    "    feature_data['min_price'] = min_price\n",
    "    feature_data['mean_price'] = mean_price\n",
    "    feature_data['std_price'] = std_price\n",
    "    feature_data['max_eta'] = max_eta\n",
    "    feature_data['min_eta'] = min_eta\n",
    "    feature_data['mean_eta'] = mean_eta\n",
    "    feature_data['std_eta'] = std_eta\n",
    "    feature_data['max_dist_mode'] = max_dist_mode\n",
    "    feature_data['min_dist_mode'] = min_dist_mode\n",
    "    feature_data['max_price_mode'] = max_price_mode\n",
    "    feature_data['min_price_mode'] = min_price_mode\n",
    "    feature_data['max_eta_mode'] = max_eta_mode\n",
    "    feature_data['min_eta_mode'] = min_eta_mode\n",
    "    feature_data['first_mode'] = first_mode\n",
    "    print('mode tfidf...')\n",
    "    tfidf_enc = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    tfidf_vec = tfidf_enc.fit_transform(mode_texts)\n",
    "    svd_enc = TruncatedSVD(n_components=10, n_iter=20, random_state=2019)\n",
    "    mode_svd = svd_enc.fit_transform(tfidf_vec)\n",
    "    mode_svd = pd.DataFrame(mode_svd)\n",
    "    mode_svd.columns = ['svd_mode_{}'.format(i) for i in range(10)]\n",
    "    plan_fea = pd.concat([feature_data, mode_svd], axis=1)\n",
    "    plan_fea['sid'] = data['sid'].values\n",
    "\n",
    "    return plan_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:04.078791Z",
     "start_time": "2019-05-01T16:59:04.071719Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rM7o4e5JCvXn"
   },
   "outputs": [],
   "source": [
    "mainpath = project_path+r'Data/data_set_phase1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:09.193297Z",
     "start_time": "2019-05-01T16:59:04.584982Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HxBaCBRxCvXo"
   },
   "outputs": [],
   "source": [
    "train_queries, train_plans, train_clicks, profiles, test_queries, test_plans = load_data(\n",
    "    mainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:11.002349Z",
     "start_time": "2019-05-01T16:59:09.375756Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wfxInGIJCvXq"
   },
   "outputs": [],
   "source": [
    "train, test, data = merge(train_queries, train_plans,\n",
    "                          train_clicks, profiles, test_queries, test_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:11.982960Z",
     "start_time": "2019-05-01T16:59:11.965288Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1QIdrjCiCvXw"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['time_diff'] = df['plan_time'].astype(\n",
    "        int) - df['req_time'].astype(int)\n",
    "\n",
    "    df['plans_json'] = data['plans'].fillna(\n",
    "        '[]').apply(lambda x: json.loads(x))\n",
    "    df_plans = gen_plan_feas(df)\n",
    "    plan_features = [col for col in df_plans.columns if col not in ['sid']]\n",
    "    df = df.merge(df_plans, on='sid', how='left')\n",
    "\n",
    "    df['req_time'] = pd.to_datetime(df['req_time'])\n",
    "    df['day_of_week'] = df['req_time'].dt.day_name()\n",
    "    df['req_date'] = df['req_time'].dt.strftime('%m-%d')\n",
    "    df['req_hour'] = df['req_time'].dt.hour\n",
    "    df['req_minute'] = df['req_time'].dt.minute\n",
    "    df['if_holiday'] = (df['req_date'].isin(holidays)).astype(int)\n",
    "\n",
    "    # Week day\n",
    "    current_c = list(df.columns.values)\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday',\n",
    "                'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    current_c.extend(weekdays)\n",
    "    df = df.reindex(columns=current_c, fill_value=0)\n",
    "    for day_name in weekdays:\n",
    "        df.loc[(df['day_of_week'] == day_name), [day_name]] = 1\n",
    "    print('week day Done.')\n",
    "\n",
    "    # Hour\n",
    "    current_c = list(df.columns.values)\n",
    "    oclock = [str(i)+'_oclock' for i in range(0, 24)]\n",
    "    current_c.extend(oclock)\n",
    "    df = df.reindex(columns=current_c, fill_value=0)\n",
    "    for h in oclock:\n",
    "        df.loc[(df['req_hour'] == int(h.split('_')[0])), [h]] = 1\n",
    "\n",
    "    print('Hour Done.')\n",
    "\n",
    "    df.drop(columns=['day_of_week', 'req_date', 'req_hour'], inplace=True)\n",
    "\n",
    "    df['o_lng'] = df['o'].apply(lambda x: float(x.split(',')[0]))\n",
    "    df['o_lat'] = df['o'].apply(lambda x: float(x.split(',')[1]))\n",
    "    df['d_lng'] = df['d'].apply(lambda x: float(x.split(',')[0]))\n",
    "    df['d_lat'] = df['d'].apply(lambda x: float(x.split(',')[1]))\n",
    "    df['od_manhattan_distance'] = abs(\n",
    "        df['o_lng']-df['d_lng'])+abs(df['o_lat']-df['d_lat'])\n",
    "\n",
    "    print('OD distance done.')\n",
    "\n",
    "    return df, weekdays, oclock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:02:38.336236Z",
     "start_time": "2019-05-01T16:59:13.893099Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2393,
     "status": "error",
     "timestamp": 1556727019156,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "BplV1S9vCvXy",
    "outputId": "064ba387-36cc-4067-b32b-de7f2c86fa75"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "594358it [02:46, 3565.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mode tfidf...\n",
      "week day Done.\n",
      "Hour Done.\n",
      "OD distance done.\n"
     ]
    }
   ],
   "source": [
    "data, weekdays, oclock = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:02:39.026542Z",
     "start_time": "2019-05-01T17:02:39.017917Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['click_mode', 'click_time', 'd', 'o', 'pid', 'plan_time', 'plans',\n",
       "       'req_time', 'sid', 'p0', 'p1', 'p2', 'p3', 'p4', 'p5', 'p6', 'p7',\n",
       "       'p8', 'p9', 'p10', 'p11', 'p12', 'p13', 'p14', 'p15', 'p16', 'p17',\n",
       "       'p18', 'p19', 'p20', 'p21', 'p22', 'p23', 'p24', 'p25', 'p26',\n",
       "       'p27', 'p28', 'p29', 'p30', 'p31', 'p32', 'p33', 'p34', 'p35',\n",
       "       'p36', 'p37', 'p38', 'p39', 'p40', 'p41', 'p42', 'p43', 'p44',\n",
       "       'p45', 'p46', 'p47', 'p48', 'p49', 'p50', 'p51', 'p52', 'p53',\n",
       "       'p54', 'p55', 'p56', 'p57', 'p58', 'p59', 'p60', 'p61', 'p62',\n",
       "       'p63', 'p64', 'p65', 'time_diff', 'plans_json', 'mode_feas_0',\n",
       "       'mode_feas_1', 'mode_feas_2', 'mode_feas_3', 'mode_feas_4',\n",
       "       'mode_feas_5', 'mode_feas_6', 'mode_feas_7', 'mode_feas_8',\n",
       "       'mode_feas_9', 'mode_feas_10', 'mode_feas_11', 'max_dist',\n",
       "       'min_dist', 'mean_dist', 'std_dist', 'max_price', 'min_price',\n",
       "       'mean_price', 'std_price', 'max_eta', 'min_eta', 'mean_eta',\n",
       "       'std_eta', 'max_dist_mode', 'min_dist_mode', 'max_price_mode',\n",
       "       'min_price_mode', 'max_eta_mode', 'min_eta_mode', 'first_mode',\n",
       "       'svd_mode_0', 'svd_mode_1', 'svd_mode_2', 'svd_mode_3',\n",
       "       'svd_mode_4', 'svd_mode_5', 'svd_mode_6', 'svd_mode_7',\n",
       "       'svd_mode_8', 'svd_mode_9', 'req_minute', 'if_holiday', 'Monday',\n",
       "       'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday',\n",
       "       '0_oclock', '1_oclock', '2_oclock', '3_oclock', '4_oclock',\n",
       "       '5_oclock', '6_oclock', '7_oclock', '8_oclock', '9_oclock',\n",
       "       '10_oclock', '11_oclock', '12_oclock', '13_oclock', '14_oclock',\n",
       "       '15_oclock', '16_oclock', '17_oclock', '18_oclock', '19_oclock',\n",
       "       '20_oclock', '21_oclock', '22_oclock', '23_oclock', 'o_lng',\n",
       "       'o_lat', 'd_lng', 'd_lat', 'od_manhattan_distance'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:02:39.710509Z",
     "start_time": "2019-05-01T17:02:39.704852Z"
    }
   },
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj, pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else:  # 我们假设这不是一个df，而是一个 Series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2  # 将 bytes 转化成 megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:02:41.446896Z",
     "start_time": "2019-05-01T17:02:40.381242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "521.48 MB\n",
      "263.01 MB\n"
     ]
    }
   ],
   "source": [
    "data_float = data.select_dtypes(include=['float'])\n",
    "converted_float = data_float.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "print(mem_usage(data_float))\n",
    "print(mem_usage(converted_float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:03:01.973999Z",
     "start_time": "2019-05-01T17:02:42.307429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1068.29 MB\n",
      "809.82 MB\n"
     ]
    }
   ],
   "source": [
    "optimized_data = data.copy()\n",
    "\n",
    "optimized_data[converted_float.columns] = converted_float\n",
    "\n",
    "print(mem_usage(data))\n",
    "print(mem_usage(optimized_data))\n",
    "data = optimized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-01T16:46:57.236Z"
    }
   },
   "source": [
    "# Add station distance feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## count origin distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T17:09:06.926785Z",
     "start_time": "2019-05-01T17:09:06.863111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5649"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data['o'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T16:59:12.932700Z",
     "start_time": "2019-05-01T16:59:12.922926Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "G44cljzSKJJf"
   },
   "outputs": [],
   "source": [
    "def count_distance(df):\n",
    "\n",
    "    df['o_nearest_dis'] = np.nan\n",
    "    df['d_nearest_dis'] = np.nan\n",
    "\n",
    "    print('Find nearest station...')\n",
    "\n",
    "    for index in df.index:\n",
    "        df[index, 'o_nearest_dis'] = (abs(subwayinfo['station_longitude']-df.loc[index]\n",
    "                                          ['o_lng'])+abs(subwayinfo['station_latitude']-df.loc[index]['o_lat'])).min()\n",
    "        df[index, 'd_nearest_dis'] = (abs(subwayinfo['station_longitude']-df.loc[index]\n",
    "                                          ['d_lng'])+abs(subwayinfo['station_latitude']-df.loc[index]['d_lat'])).min()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rsLlF6-UCvXz"
   },
   "outputs": [],
   "source": [
    "profile_feature = ['p' + str(i) for i in range(66)]\n",
    "origin_num_feature = ['o_lng', 'o_lat', 'd_lng', 'd_lat',\n",
    "                      'od_manhattan_distance', 'o_nearest_dis', 'd_nearest_dis'] + profile_feature\n",
    "# cate_feature       = ['pid']\n",
    "time_feature = weekdays+oclock\n",
    "feature = origin_num_feature + plan_features + time_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYh6IcyBCvX1"
   },
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e_GiAJWUCvX1"
   },
   "outputs": [],
   "source": [
    "train_index = (data.req_time < '2018-11-23')\n",
    "train_x = data[train_index][feature].reset_index(drop=True)\n",
    "train_y = data[train_index].click_mode.reset_index(drop=True)\n",
    "\n",
    "valid_index = (data.req_time > '2018-11-23') & (data.req_time < '2018-12-01')\n",
    "valid_x = data[valid_index][feature].reset_index(drop=True)\n",
    "valid_y = data[valid_index].click_mode.reset_index(drop=True)\n",
    "\n",
    "test_index = (data.req_time > '2018-12-01')\n",
    "test_x = data[test_index][feature].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7lCjcXYCvX3"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-01T13:56:40.943469Z",
     "start_time": "2019-05-01T13:56:40.870679Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dmVtqDJHCvXl"
   },
   "outputs": [],
   "source": [
    "def f1_weighted(labels, preds):\n",
    "    preds = np.argmax(preds.reshape(12, -1), axis=0)\n",
    "    score = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_weighted', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IaN5aeUZCvX4"
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(boosting_type=\"gbdt\",\n",
    "                               num_leaves=61,\n",
    "                               reg_alpha=0,\n",
    "                               reg_lambda=0.01,\n",
    "                               max_depth=-1,\n",
    "                               n_estimators=2000,\n",
    "                               objective='multiclass',\n",
    "                               subsample=0.8,\n",
    "                               colsample_bytree=0.8,\n",
    "                               subsample_freq=1,\n",
    "                               min_child_samples=50,\n",
    "                               learning_rate=0.05,\n",
    "                               random_state=2019,\n",
    "                               metric=\"None\",\n",
    "                               n_jobs=-1)\n",
    "eval_set = [(valid_x, valid_y)]\n",
    "lgb_model.fit(train_x, train_y, eval_set=eval_set, eval_metric=f1_weighted,\n",
    "              categorical_feature=cate_feature, verbose=10, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDIviFYVCvX6"
   },
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vXy7U40ECvX7"
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame()\n",
    "imp['fea'] = feature\n",
    "imp['imp'] = lgb_model.feature_importances_\n",
    "imp = imp.sort_values('imp', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(20, 100))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"feature\",\n",
    "            data=imp)\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UAV2I0HCvX8"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6FQLgnBzCvX9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "pred = lgb_model.predict(valid_x)\n",
    "df_analysis = pd.DataFrame()\n",
    "df_analysis['sid'] = data[valid_index]['sid']\n",
    "df_analysis['label'] = valid_y.values\n",
    "df_analysis['pred'] = pred\n",
    "df_analysis['label'] = df_analysis['label'].astype(int)\n",
    "dic_ = df_analysis['label'].value_counts(normalize=True)\n",
    "\n",
    "\n",
    "def get_weighted_fscore(y_pred, y_true):\n",
    "    f_score = 0\n",
    "    for i in range(12):\n",
    "        yt = y_true == i\n",
    "        yp = y_pred == i\n",
    "        f_score += dic_[i] * f1_score(y_true=yt, y_pred=yp)\n",
    "        print(i, dic_[i], f1_score(y_true=yt, y_pred=yp), precision_score(\n",
    "            y_true=yt, y_pred=yp), recall_score(y_true=yt, y_pred=yp))\n",
    "    print(f_score)\n",
    "\n",
    "\n",
    "get_weighted_fscore(y_true=df_analysis['label'], y_pred=df_analysis['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xVhOpSZeCvX_"
   },
   "outputs": [],
   "source": [
    "all_train_x = data[data.req_time <\n",
    "                   '2018-12-01'][feature].reset_index(drop=True)\n",
    "all_train_y = data[data.req_time <\n",
    "                   '2018-12-01'].click_mode.reset_index(drop=True)\n",
    "print(lgb_model.best_iteration_)\n",
    "lgb_model.n_estimators = lgb_model.best_iteration_\n",
    "lgb_model.fit(all_train_x, all_train_y, categorical_feature=cate_feature)\n",
    "print('fit over')\n",
    "result = pd.DataFrame()\n",
    "result['sid'] = data[test_index]['sid']\n",
    "result['recommend_mode'] = lgb_model.predict(test_x)\n",
    "result['recommend_mode'] = result['recommend_mode'].astype(int)\n",
    "print(len(result))\n",
    "print(result['recommend_mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XfZbGMgHCvYC"
   },
   "outputs": [],
   "source": [
    "result[['sid', 'recommend_mode']].to_csv(\n",
    "    path + '/sub/baseline.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pipline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
