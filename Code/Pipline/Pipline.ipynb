{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:06:57.724051Z",
     "start_time": "2019-05-03T19:06:57.721019Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 75401,
     "status": "error",
     "timestamp": 1556727122761,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "H4_rgcWjC1wQ",
    "outputId": "4f67fd54-1f4d-4f3d-c880-0db8b5ab9e3e"
   },
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# from oauth2client.client import GoogleCredentials\n",
    "# from google.colab import auth\n",
    "# !apt-get install - y - qq software-properties-common python-software-properties module-init-tools\n",
    "# !add-apt-repository - y ppa: alessandro-strada/ppa 2 > &1 > /dev/null\n",
    "# !apt-get update - qq 2 > &1 > /dev/null\n",
    "# !apt-get - y install - qq google-drive-ocamlfuse fuse\n",
    "# auth.authenticate_user()\n",
    "# creds = GoogleCredentials.get_application_default()\n",
    "# !google-drive-ocamlfuse - headless - id = {creds.client_id} - secret = {creds.client_secret} < /dev/null 2 > &1 | grep URL\n",
    "# vcode = getpass.getpass()\n",
    "# !echo {vcode} | google-drive-ocamlfuse - headless - id = {creds.client_id} - secret = {creds.client_secret}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:06:57.934306Z",
     "start_time": "2019-05-03T19:06:57.732154Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "sAEXzMr_DOTo"
   },
   "outputs": [],
   "source": [
    "# !mkdir - p drive\n",
    "# !google-drive-ocamlfuse drive - o nonempty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:06:58.067080Z",
     "start_time": "2019-05-03T19:06:57.937595Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "MCDdayZDDVVs"
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T19:06:58.121997Z",
     "start_time": "2019-05-03T19:06:58.070221Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3270,
     "status": "ok",
     "timestamp": 1556727041091,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "6AH8_4oADX8R",
    "outputId": "de369089-fcfc-4d3d-8fbd-17517f9d4a92"
   },
   "outputs": [],
   "source": [
    "# !ls Competitions/KDD-Cup-2019-CAMMTR/Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.734Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "OxlyOW7bCvXc"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# project_path='./Competitions/KDD-Cup-2019-CAMMTR/'\n",
    "project_path = '../../'\n",
    "\n",
    "holidays = pd.Series(\n",
    "    json.load(open(project_path+r'Data/Holidays.json'))['holidays'])\n",
    "subwayinfo = pd.read_csv(project_path+r'Data/BeijingSubway.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AJFW6SL_CvXf"
   },
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.737Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "kCAkXW4fCvXg"
   },
   "outputs": [],
   "source": [
    "def load_data(mainpath):\n",
    "    train_queries = pd.read_csv(\n",
    "        mainpath + 'train_queries.csv', parse_dates=['req_time'])\n",
    "    train_plans = pd.read_csv(mainpath + 'train_plans.csv',\n",
    "                              parse_dates=['plan_time'])\n",
    "    train_clicks = pd.read_csv(mainpath + 'train_clicks.csv')\n",
    "    profiles = pd.read_csv(mainpath + 'profiles.csv')\n",
    "    test_queries = pd.read_csv(\n",
    "        mainpath + 'test_queries.csv', parse_dates=['req_time'])\n",
    "    test_plans = pd.read_csv(mainpath + 'test_plans.csv',\n",
    "                             parse_dates=['plan_time'])\n",
    "    return train_queries, train_plans, train_clicks, profiles, test_queries, test_plans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.741Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "iUQcoS3ACvXi"
   },
   "outputs": [],
   "source": [
    "def merge(train_queries, train_plans, train_clicks, profiles, test_queries, test_plans):\n",
    "    train = train_queries.merge(train_plans, 'left', ['sid'])\n",
    "    test = test_queries.merge(test_plans, 'left', ['sid'])\n",
    "    train = train.merge(train_clicks, 'left', ['sid'])\n",
    "    train['click_mode'] = train['click_mode'].fillna(0).astype(int)\n",
    "    data = pd.concat([train, test], ignore_index=True)\n",
    "    data = data.merge(profiles, 'left', ['pid'])\n",
    "    return train, test, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.745Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ezvgAZ46CvXj"
   },
   "outputs": [],
   "source": [
    "def gen_plan_feas(data):\n",
    "    n = data.shape[0]\n",
    "    mode_list_feas = np.zeros((n, 12))\n",
    "    max_dist, min_dist, mean_dist, std_dist = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    max_price, min_price, mean_price, std_price = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    max_eta, min_eta, mean_eta, std_eta = np.zeros(\n",
    "        (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    min_dist_mode, max_dist_mode, min_price_mode, max_price_mode, min_eta_mode, max_eta_mode, first_mode = \\\n",
    "        np.zeros((n,)), np.zeros((n,)), np.zeros((n,)), np.zeros(\n",
    "            (n,)), np.zeros((n,)), np.zeros((n,)), np.zeros((n,))\n",
    "\n",
    "    mode_texts = []\n",
    "    for i, plan in tqdm(enumerate(data['plans_json'].values)):\n",
    "        if len(plan) == 0:\n",
    "            cur_plan_list = []\n",
    "        else:\n",
    "            cur_plan_list = plan\n",
    "        if len(cur_plan_list) == 0:\n",
    "            mode_list_feas[i, 0] = 1\n",
    "            first_mode[i] = 0\n",
    "            max_dist[i] = -1\n",
    "            min_dist[i] = -1\n",
    "            mean_dist[i] = -1\n",
    "            std_dist[i] = -1\n",
    "            max_price[i] = -1\n",
    "            min_price[i] = -1\n",
    "            mean_price[i] = -1\n",
    "            std_price[i] = -1\n",
    "            max_eta[i] = -1\n",
    "            min_eta[i] = -1\n",
    "            mean_eta[i] = -1\n",
    "            std_eta[i] = -1\n",
    "            min_dist_mode[i] = -1\n",
    "            max_dist_mode[i] = -1\n",
    "            min_price_mode[i] = -1\n",
    "            max_price_mode[i] = -1\n",
    "            min_eta_mode[i] = -1\n",
    "            max_eta_mode[i] = -1\n",
    "            mode_texts.append('word_null')\n",
    "        else:\n",
    "            distance_list = []\n",
    "            price_list = []\n",
    "            eta_list = []\n",
    "            mode_list = []\n",
    "            for tmp_dit in cur_plan_list:\n",
    "                distance_list.append(int(tmp_dit['distance']))\n",
    "                if tmp_dit['price'] == '':\n",
    "                    price_list.append(0)\n",
    "                else:\n",
    "                    price_list.append(int(tmp_dit['price']))\n",
    "                eta_list.append(int(tmp_dit['eta']))\n",
    "                mode_list.append(int(tmp_dit['transport_mode']))\n",
    "            mode_texts.append(\n",
    "                ' '.join(['word_{}'.format(mode) for mode in mode_list]))\n",
    "            distance_list = np.array(distance_list)\n",
    "            price_list = np.array(price_list)\n",
    "            eta_list = np.array(eta_list)\n",
    "            mode_list = np.array(mode_list, dtype='int')\n",
    "            mode_list_feas[i, mode_list] = 1\n",
    "            distance_sort_idx = np.argsort(distance_list)\n",
    "            price_sort_idx = np.argsort(price_list)\n",
    "            eta_sort_idx = np.argsort(eta_list)\n",
    "            max_dist[i] = distance_list[distance_sort_idx[-1]]\n",
    "            min_dist[i] = distance_list[distance_sort_idx[0]]\n",
    "            mean_dist[i] = np.mean(distance_list)\n",
    "            std_dist[i] = np.std(distance_list)\n",
    "            max_price[i] = price_list[price_sort_idx[-1]]\n",
    "            min_price[i] = price_list[price_sort_idx[0]]\n",
    "            mean_price[i] = np.mean(price_list)\n",
    "            std_price[i] = np.std(price_list)\n",
    "            max_eta[i] = eta_list[eta_sort_idx[-1]]\n",
    "            min_eta[i] = eta_list[eta_sort_idx[0]]\n",
    "            mean_eta[i] = np.mean(eta_list)\n",
    "            std_eta[i] = np.std(eta_list)\n",
    "            first_mode[i] = mode_list[0]\n",
    "            max_dist_mode[i] = mode_list[distance_sort_idx[-1]]\n",
    "            min_dist_mode[i] = mode_list[distance_sort_idx[0]]\n",
    "            max_price_mode[i] = mode_list[price_sort_idx[-1]]\n",
    "            min_price_mode[i] = mode_list[price_sort_idx[0]]\n",
    "            max_eta_mode[i] = mode_list[eta_sort_idx[-1]]\n",
    "            min_eta_mode[i] = mode_list[eta_sort_idx[0]]\n",
    "    feature_data = pd.DataFrame(mode_list_feas)\n",
    "    feature_data.columns = ['mode_feas_{}'.format(i) for i in range(12)]\n",
    "    feature_data['max_dist'] = max_dist\n",
    "    feature_data['min_dist'] = min_dist\n",
    "    feature_data['mean_dist'] = mean_dist\n",
    "    feature_data['std_dist'] = std_dist\n",
    "    feature_data['max_price'] = max_price\n",
    "    feature_data['min_price'] = min_price\n",
    "    feature_data['mean_price'] = mean_price\n",
    "    feature_data['std_price'] = std_price\n",
    "    feature_data['max_eta'] = max_eta\n",
    "    feature_data['min_eta'] = min_eta\n",
    "    feature_data['mean_eta'] = mean_eta\n",
    "    feature_data['std_eta'] = std_eta\n",
    "    feature_data['max_dist_mode'] = max_dist_mode\n",
    "    feature_data['min_dist_mode'] = min_dist_mode\n",
    "    feature_data['max_price_mode'] = max_price_mode\n",
    "    feature_data['min_price_mode'] = min_price_mode\n",
    "    feature_data['max_eta_mode'] = max_eta_mode\n",
    "    feature_data['min_eta_mode'] = min_eta_mode\n",
    "    feature_data['first_mode'] = first_mode\n",
    "    print('mode tfidf...')\n",
    "    tfidf_enc = TfidfVectorizer(ngram_range=(1, 2))\n",
    "    tfidf_vec = tfidf_enc.fit_transform(mode_texts)\n",
    "    svd_enc = TruncatedSVD(n_components=10, n_iter=20, random_state=2019)\n",
    "    mode_svd = svd_enc.fit_transform(tfidf_vec)\n",
    "    mode_svd = pd.DataFrame(mode_svd)\n",
    "    mode_svd.columns = ['svd_mode_{}'.format(i) for i in range(10)]\n",
    "    plan_fea = pd.concat([feature_data, mode_svd], axis=1)\n",
    "    plan_fea['sid'] = data['sid'].values\n",
    "\n",
    "    return plan_fea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.748Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rM7o4e5JCvXn"
   },
   "outputs": [],
   "source": [
    "mainpath = project_path + r'Data/data_set_phase1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.751Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HxBaCBRxCvXo"
   },
   "outputs": [],
   "source": [
    "train_queries, train_plans, train_clicks, profiles, test_queries, test_plans = load_data(\n",
    "    mainpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.754Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "wfxInGIJCvXq"
   },
   "outputs": [],
   "source": [
    "train, test, data = merge(train_queries, train_plans,\n",
    "                          train_clicks, profiles, test_queries, test_plans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.757Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "1QIdrjCiCvXw"
   },
   "outputs": [],
   "source": [
    "def feature_engineering(df):\n",
    "    df['time_diff'] = df['plan_time'].astype(\n",
    "        int) - df['req_time'].astype(int)\n",
    "\n",
    "    df['plans_json'] = data['plans'].fillna(\n",
    "        '[]').apply(lambda x: json.loads(x))\n",
    "    df_plans = gen_plan_feas(df)\n",
    "    plan_features = [col for col in df_plans.columns if col not in ['sid']]\n",
    "    df = df.merge(df_plans, on='sid', how='left')\n",
    "\n",
    "    df['req_time'] = pd.to_datetime(df['req_time'])\n",
    "    df['day_of_week'] = df['req_time'].dt.day_name()\n",
    "    df['req_date'] = df['req_time'].dt.strftime('%m-%d')\n",
    "    df['req_hour'] = df['req_time'].dt.hour\n",
    "    df['req_minute'] = df['req_time'].dt.minute\n",
    "    df['if_holiday'] = (df['req_date'].isin(holidays)).astype(int)\n",
    "\n",
    "    # Week day\n",
    "    current_c = list(df.columns.values)\n",
    "    weekdays = ['Monday', 'Tuesday', 'Wednesday',\n",
    "                'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    current_c.extend(weekdays)\n",
    "    df = df.reindex(columns=current_c, fill_value=0)\n",
    "    for day_name in weekdays:\n",
    "        df.loc[(df['day_of_week'] == day_name), [day_name]] = 1\n",
    "    print('week day Done.')\n",
    "\n",
    "    # Hour\n",
    "    current_c = list(df.columns.values)\n",
    "    oclock = [str(i)+'_oclock' for i in range(0, 24)]\n",
    "    current_c.extend(oclock)\n",
    "    df = df.reindex(columns=current_c, fill_value=0)\n",
    "    for h in oclock:\n",
    "        df.loc[(df['req_hour'] == int(h.split('_')[0])), [h]] = 1\n",
    "\n",
    "    print('Hour Done.')\n",
    "\n",
    "    df.drop(columns=['day_of_week', 'req_date', 'req_hour'], inplace=True)\n",
    "\n",
    "    df['o_lng'] = df['o'].apply(lambda x: float(x.split(',')[0]))\n",
    "    df['o_lat'] = df['o'].apply(lambda x: float(x.split(',')[1]))\n",
    "    df['d_lng'] = df['d'].apply(lambda x: float(x.split(',')[0]))\n",
    "    df['d_lat'] = df['d'].apply(lambda x: float(x.split(',')[1]))\n",
    "    df['od_manhattan_distance'] = abs(\n",
    "        df['o_lng']-df['d_lng'])+abs(df['o_lat']-df['d_lat'])\n",
    "\n",
    "    print('OD distance done.')\n",
    "\n",
    "    return df, weekdays, oclock, plan_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.760Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2393,
     "status": "error",
     "timestamp": 1556727019156,
     "user": {
      "displayName": "Alan Lau",
      "photoUrl": "https://lh3.googleusercontent.com/-ZaOsrA7oyQw/AAAAAAAAAAI/AAAAAAAAAAc/PW0qJYFKbUY/s64/photo.jpg",
      "userId": "02808478473948384287"
     },
     "user_tz": -480
    },
    "id": "BplV1S9vCvXy",
    "outputId": "064ba387-36cc-4067-b32b-de7f2c86fa75"
   },
   "outputs": [],
   "source": [
    "data, weekdays, oclock, plan_features = feature_engineering(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reduce memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.764Z"
    }
   },
   "outputs": [],
   "source": [
    "def mem_usage(pandas_obj):\n",
    "    if isinstance(pandas_obj, pd.DataFrame):\n",
    "        usage_b = pandas_obj.memory_usage(deep=True).sum()\n",
    "    else:  # 我们假设这不是一个df，而是一个 Series\n",
    "        usage_b = pandas_obj.memory_usage(deep=True)\n",
    "    usage_mb = usage_b / 1024 ** 2  # 将 bytes 转化成 megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.767Z"
    }
   },
   "outputs": [],
   "source": [
    "data_float = data.select_dtypes(include=['float'])\n",
    "converted_float = data_float.apply(pd.to_numeric, downcast='float')\n",
    "\n",
    "print(mem_usage(data_float))\n",
    "print(mem_usage(converted_float))\n",
    "\n",
    "optimized_data = data.copy()\n",
    "\n",
    "optimized_data[converted_float.columns] = converted_float\n",
    "\n",
    "print(mem_usage(data))\n",
    "print(mem_usage(optimized_data))\n",
    "data = optimized_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-03T04:22:32.301017Z",
     "start_time": "2019-05-03T04:22:32.296715Z"
    }
   },
   "source": [
    "# Add Centroid distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.770Z"
    }
   },
   "outputs": [],
   "source": [
    "o_co = data[['o']]\n",
    "d_co = data[['d']]\n",
    "\n",
    "o_co.columns = ['co']\n",
    "d_co.columns = ['co']\n",
    "\n",
    "all_co = pd.concat([d_co, o_co]).drop_duplicates()\n",
    "all_co.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.773Z"
    }
   },
   "outputs": [],
   "source": [
    "all_co['lng'] = all_co['co'].apply(lambda x: float(x.split(',')[0]))\n",
    "all_co['lat'] = all_co['co'].apply(lambda x: float(x.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.777Z"
    }
   },
   "outputs": [],
   "source": [
    "all_co.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.782Z"
    }
   },
   "outputs": [],
   "source": [
    "lng_mean = all_co['lng'].mean()\n",
    "lat_mean = all_co['lat'].mean()\n",
    "\n",
    "lng_mode = all_co['lng'].mode()[0]\n",
    "lat_mode = all_co['lat'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.786Z"
    }
   },
   "outputs": [],
   "source": [
    "data['o_main_centroid_mean_dis'] = abs(\n",
    "    data['o_lng']-lng_mean)+abs(data['o_lat']-lat_mean)\n",
    "data['d_main_centroid_mean_dis'] = abs(\n",
    "    data['d_lng']-lng_mean)+abs(data['d_lat']-lat_mean)\n",
    "\n",
    "data['o_main_centroid_mode_dis'] = abs(\n",
    "    data['o_lng']-lng_meann)+abs(data['o_lat']-lat_mea)\n",
    "data['d_main_centroid_mode_dis'] = abs(\n",
    "    data['d_lng']-lng_mode)+abs(data['d_lat']-lat_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-01T16:46:57.236Z"
    }
   },
   "source": [
    "# Add station distance feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.791Z"
    }
   },
   "outputs": [],
   "source": [
    "data['o_nearest_dis'] = np.nan\n",
    "data['d_nearest_dis'] = np.nan\n",
    "\n",
    "for co in tqdm(data['o'].unique()):\n",
    "    lg, la = co.split(',')\n",
    "    min_dis = (abs(subwayinfo['station_longitude']-float(lg)) +\n",
    "               abs(subwayinfo['station_latitude']-float(la))).min()\n",
    "    data.loc[(data['o'] == co), 'o_nearest_dis'] = min_dis\n",
    "\n",
    "\n",
    "for co in tqdm(data['d'].unique()):\n",
    "    lg, la = co.split(',')\n",
    "    min_dis = (abs(subwayinfo['station_longitude']-float(lg)) +\n",
    "               abs(subwayinfo['station_latitude']-float(la))).min()\n",
    "    data.loc[(data['d'] == co), 'd_nearest_dis'] = min_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.796Z"
    }
   },
   "outputs": [],
   "source": [
    "data.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.801Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "rsLlF6-UCvXz"
   },
   "outputs": [],
   "source": [
    "profile_feature = ['p' + str(i) for i in range(66)]\n",
    "origin_num_feature = ['o_lng', 'o_lat', 'd_lng', 'd_lat', 'o_main_centroid_mean_dis',\n",
    "                      'd_main_centroid_mean_dis', 'o_main_centroid_mode_dis', 'd_main_centroid_mode_dis',\n",
    "                      'od_manhattan_distance', 'o_nearest_dis', 'd_nearest_dis'] + profile_feature\n",
    "cate_feature = ['pid']\n",
    "time_feature = weekdays + oclock + ['if_holiday']\n",
    "feature = origin_num_feature + plan_features + time_feature+cate_feature\n",
    "print('Got %s features' % str(len(feature)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.805Z"
    }
   },
   "outputs": [],
   "source": [
    "# for p in profile_feature:\n",
    "#     data[p].fillna(data[p].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kYh6IcyBCvX1"
   },
   "source": [
    "# Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.810Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "e_GiAJWUCvX1"
   },
   "outputs": [],
   "source": [
    "train_index = (data.req_time < '2018-11-23')\n",
    "train_x = data[train_index][feature].reset_index(drop=True)\n",
    "train_y = data[train_index].click_mode.reset_index(drop=True)\n",
    "\n",
    "valid_index = (data.req_time > '2018-11-23') & (data.req_time < '2018-12-01')\n",
    "valid_x = data[valid_index][feature].reset_index(drop=True)\n",
    "valid_y = data[valid_index].click_mode.reset_index(drop=True)\n",
    "\n",
    "test_index = (data.req_time > '2018-12-01')\n",
    "test_x = data[test_index][feature].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J7lCjcXYCvX3"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.815Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "dmVtqDJHCvXl"
   },
   "outputs": [],
   "source": [
    "def f1_weighted(labels, preds):\n",
    "    preds = np.argmax(preds.reshape(12, -1), axis=0)\n",
    "    score = f1_score(y_true=labels, y_pred=preds, average='weighted')\n",
    "    return 'f1_weighted', score, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.818Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IaN5aeUZCvX4"
   },
   "outputs": [],
   "source": [
    "lgb_model = lgb.LGBMClassifier(boosting_type=\"gbdt\",\n",
    "                               num_leaves=61,\n",
    "                               reg_alpha=0,\n",
    "                               reg_lambda=0.01,\n",
    "                               max_depth=-1,\n",
    "                               n_estimators=2000,\n",
    "                               objective='multiclass',\n",
    "                               subsample=0.8,\n",
    "                               colsample_bytree=0.8,\n",
    "                               subsample_freq=1,\n",
    "                               min_child_samples=50,\n",
    "                               learning_rate=0.05,\n",
    "                               random_state=2019,\n",
    "                               metric=\"None\",\n",
    "                               n_jobs=-1)\n",
    "# 2: 0.687966\n",
    "# 3: 0.687585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.822Z"
    }
   },
   "outputs": [],
   "source": [
    "eval_set = [(valid_x, valid_y)]\n",
    "lgb_model.fit(train_x, train_y, eval_set=eval_set, eval_metric=f1_weighted,\n",
    "              categorical_feature=cate_feature, verbose=10, early_stopping_rounds=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sDIviFYVCvX6"
   },
   "source": [
    "# Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.827Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "vXy7U40ECvX7"
   },
   "outputs": [],
   "source": [
    "imp = pd.DataFrame()\n",
    "imp['features'] = feature\n",
    "imp['importance'] = lgb_model.feature_importances_\n",
    "imp = imp.sort_values('importance', ascending=False)\n",
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.830Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 100))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"features\",\n",
    "            data=imp)\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8UAV2I0HCvX8"
   },
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.834Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6FQLgnBzCvX9"
   },
   "outputs": [],
   "source": [
    "pred = lgb_model.predict(valid_x)\n",
    "df_analysis = pd.DataFrame()\n",
    "df_analysis['sid'] = data[valid_index]['sid']\n",
    "df_analysis['label'] = valid_y.values\n",
    "df_analysis['pred'] = pred\n",
    "df_analysis['label'] = df_analysis['label'].astype(int)\n",
    "dic_ = df_analysis['label'].value_counts(normalize=True)\n",
    "\n",
    "score_df = pd.DataFrame(\n",
    "    columns=['class_id', 'counts*f1_score', 'f1_score', 'precision', 'recall'])\n",
    "\n",
    "\n",
    "def get_weighted_fscore(y_pred, y_true):\n",
    "    f_score = 0\n",
    "    for i in range(12):\n",
    "        yt = y_true == i\n",
    "        yp = y_pred == i\n",
    "        f_score += dic_[i] * f1_score(y_true=yt, y_pred=yp)\n",
    "        score_df.loc[i] = [i, dic_[i], f1_score(y_true=yt, y_pred=yp), precision_score(\n",
    "            y_true=yt, y_pred=yp), recall_score(y_true=yt, y_pred=yp)]\n",
    "    print(f_score)\n",
    "    return score_df\n",
    "\n",
    "\n",
    "score_df = get_weighted_fscore(\n",
    "    y_true=df_analysis['label'], y_pred=df_analysis['pred'])\n",
    "score_df\n",
    "\n",
    "# 0.7095882458513125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.837Z"
    }
   },
   "outputs": [],
   "source": [
    "score_df['counts*f1_score'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.841Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "xVhOpSZeCvX_"
   },
   "outputs": [],
   "source": [
    "all_train_x = data[data.req_time <\n",
    "                   '2018-12-01'][feature].reset_index(drop=True)\n",
    "all_train_y = data[data.req_time <\n",
    "                   '2018-12-01'].click_mode.reset_index(drop=True)\n",
    "print(lgb_model.best_iteration_)\n",
    "lgb_model.n_estimators = lgb_model.best_iteration_\n",
    "lgb_model.fit(all_train_x, all_train_y, categorical_feature=cate_feature)\n",
    "print('fit over')\n",
    "result = pd.DataFrame()\n",
    "result['sid'] = data[test_index]['sid']\n",
    "result['recommend_mode'] = lgb_model.predict(test_x)\n",
    "result['recommend_mode'] = result['recommend_mode'].astype(int)\n",
    "print(len(result))\n",
    "print(result['recommend_mode'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-05-03T19:06:57.843Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "XfZbGMgHCvYC"
   },
   "outputs": [],
   "source": [
    "result[['sid', 'recommend_mode']].to_csv(\n",
    "    project_path + 'Data/long_legs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Pipline.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
